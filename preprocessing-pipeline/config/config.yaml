# Configuration for MOMENT Preprocessing Pipeline

# Data paths
data:
  raw:
    user_interpretations: "data/raw/user_interpretations.csv"
    passages: "data/raw/passages.csv"
    characters: "data/raw/characters.csv"
  
  processed:
    moments: "data/processed/moments_processed.json"
    books: "data/processed/books_processed.json"
    metadata: "data/processed/metadata.json"
  
  validation:
    report: "data/validation/validation_report.json"
    log: "data/validation/processing_log.json"

# Airflow/DVC integration
airflow:
  input_dir: "data/raw"
  output_dir: "data/processed"
  
  # Function signatures (for reference)
  preprocess_books:
    input_files:
      - "passages.csv"
    output_files:
      - "books_processed.json"
  
  preprocess_moments:
    input_files:
      - "user_interpretations.csv"
      - "characters.csv"
    output_files:
      - "moments_processed.json"

# Book mapping strategy
book_lookup:
  strategy: "csv"  # Options: "csv", "gutenberg_api", "database"
  
  # Row-based mapping for CSV strategy
  row_ranges:
    - book_title: "Frankenstein"
      book_author: "Mary Shelley"
      gutenberg_id: "84"
      row_start: 0
      row_end: 149
    
    - book_title: "Pride and Prejudice"
      book_author: "Jane Austen"
      gutenberg_id: "1342"
      row_start: 150
      row_end: 299
    
    - book_title: "The Great Gatsby"
      book_author: "F. Scott Fitzgerald"
      gutenberg_id: "64317"
      row_start: 300
      row_end: 449

# Text preprocessing settings
preprocessing:
  text_cleaning:
    remove_extra_whitespace: true
    normalize_unicode: true
    fix_encoding: true
    remove_urls: false
    remove_emails: false
  
  validation:
    min_words: 10
    max_words: 500
    min_chars: 50
    max_chars: 3000
    allowed_languages: ["en"]
    quality_threshold: 0.5
  
  issue_detection:
    check_pii: true
    check_profanity: true
    check_spam: true
    profanity_threshold: 0.3

# ID generation
id_generation:
  user_id_prefix: "user"
  book_id_prefix: "gutenberg"
  passage_id_prefix: "passage"
  interpretation_id_prefix: "moment"
  hash_length: 12

# Output settings
output:
  format: "json"  # Options: "json", "jsonl"
  pretty_print: true
  include_metadata: true
  add_timestamp: true

# Logging
logging:
  level: "INFO"  # Options: "DEBUG", "INFO", "WARNING", "ERROR"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"